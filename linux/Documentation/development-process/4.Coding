4: GETTING THE CODE RIGHT

While there is much to be said for a solid and community-oriented design
process, the proof of any kernel development project is in the resulting
code.  It is the code which will be examined by other developers and merged
(or not) into the mainline tree.  So it is the quality of this code which
will determine the ultimate success of the project.
견고하고 커뮤니티 중심인 디자인 프로세스에 대해 할 말이 많지만, 
어떤 커널 개발 프로젝트의 증거는 결국 결과 코드이다. 이것은 다른 개발자들에게
리뷰받고 메인라인 트리에 머지되거나 반려된다. 그래서 프로젝트의 궁극적인 성공을
결정하는것은 이 코드의 품질이다.

This section will examine the coding process.  We'll start with a look at a
number of ways in which kernel developers can go wrong.  Then the focus
will shift toward doing things right and the tools which can help in that
quest.
이 섹션에서는 코딩 과정을 살펴 본다. 우리는 커널 개발자가 실수 할수있는
여러가지 경우를 살펴보며 시작할 것이다. 그런 다음 제대로 개발하는 법과 
작업에 도움을 줄 수있는 도구들을 살펴볼 것이다.


4.1: PITFALLS
4.1: 유의사항

* Coding style

The kernel has long had a standard coding style, described in
Documentation/CodingStyle.  For much of that time, the policies described
in that file were taken as being, at most, advisory.  As a result, there is
a substantial amount of code in the kernel which does not meet the coding
style guidelines.  The presence of that code leads to two independent
hazards for kernel developers.
커널은 Documentation/CodingStyle에 표준 코딩스타일을 오래동안 기술해 왔다. 
그 많은 시간동안 해당 파일에 설명 된 정책은 대부분의 자문정도로 간주되었다.
결과적으로 코딩 스타일 지침을 충족하지 않는 상당량의 코드가 있다. 
이런 코드의 존재는 커널 개발자들에게 두가지 위험요소를 유발할 수 있다.

The first of these is to believe that the kernel coding standards do not
matter and are not enforced.  The truth of the matter is that adding new
code to the kernel is very difficult if that code is not coded according to
the standard; many developers will request that the code be reformatted
before they will even review it.  A code base as large as the kernel
requires some uniformity of code to make it possible for developers to
quickly understand any part of it.  So there is no longer room for
strangely-formatted code.
이 중 첫 번째는 커널이 표준은 중요하지 않고 강제성이 없다고 생각하는 것이다.
문제의 진실은 코드 표준을 따르지 않은 경우 커널에 새로운 코드를 추가하기가
매우 어렵다는 것이다. 심지어 많은 개발자들은 리뷰도 하기 전에 코드 포맷팅을 요청한다.
커널만큼 큰 코드는 개발자가 가능한 빨리 그것의 일부를 이해할 수 있도록 코드균일성이
필요하고 그래서 형식을 지키지 않은 코드는 사용될 여지가 없다.

Occasionally, the kernel's coding style will run into conflict with an
employer's mandated style.  In such cases, the kernel's style will have to
win before the code can be merged.  Putting code into the kernel means
giving up a degree of control in a number of ways - including control over
how the code is formatted.
때때로, 커널의 코딩 스타일이 고용주가 원하는 스타일과 충돌할 수 있다. 
이러한 경우, 코드는 머지되기 전에 커널 스타일로 포맷팅 되어야 할 것이다. 
커널에 코드를 커밋하는 것은 코드포맷 포함하여 여러가지 제어의 포기를 의미한다.

The other trap is to assume that code which is already in the kernel is
urgently in need of coding style fixes.  Developers may start to generate
reformatting patches as a way of gaining familiarity with the process, or
as a way of getting their name into the kernel changelogs - or both.  But
pure coding style fixes are seen as noise by the development community;
they tend to get a chilly reception.  So this type of patch is best
avoided.  It is natural to fix the style of a piece of code while working
on it for other reasons, but coding style changes should not be made for
their own sake.
두번재 문제는 이미 머지된 커널코드가 긴급히 스타일 픽스를 필요로 하는 경우를 가정해보자.
개발자는 과정에 익숙해지기 위해 또는 이름을 기록에 남기기 위해 포맷팅 패치를 생성하기
시작할 것이다. 그러나 순수한 코딩 스타일 픽스는 개발 커뮤니티에겐 좋게 보이지 않을 것이다.
차가운 반응을 얻을 것이다. 따라서 이런 유형의 패치를 피해야한다. 다른 이유를 위해 패치하면서
코딩 스타일을 수정하는 것은 자연 스럽지만 코딩 스타일 패치는 이루어 져서는 안된다.

The coding style document also should not be read as an absolute law which
can never be transgressed.  If there is a good reason to go against the
style (a line which becomes far less readable if split to fit within the
80-column limit, for example), just do it.
코딩 스타일 문서는 어기면 안되는 절대적인 법처럼 여겨질 필요는 없다.
예를 들어, 80 열 제한에 맞도록 분할하면 가독성이 떨어지는 경우 꼭 표준을 지킬 필요는 없다.


* Abstraction layers

Computer Science professors teach students to make extensive use of
abstraction layers in the name of flexibility and information hiding.
Certainly the kernel makes extensive use of abstraction; no project
involving several million lines of code could do otherwise and survive.
But experience has shown that excessive or premature abstraction can be
just as harmful as premature optimization.  Abstraction should be used to
the level required and no further.
컴퓨터과학 교수는 유연성과 정보은폐를 위해 추상화 레이어를 광범위하게
사용하라고 학생들을 가르친다. 물론 커널은 추상화를 광범위하게 사용한다.
코드 만줄을 포함하는 프로젝트는 달리 할수도 없고 그러지 않으면 살아남을 수 없다. 
그러나 경험상 과도하거나 섣부른 추상화는 조기 최적화만큼 해가 될 수 있다. 
추상화는 필요한 수준으로만 사용되어야 한다.

At a simple level, consider a function which has an argument which is
always passed as zero by all callers.  One could retain that argument just
in case somebody eventually needs to use the extra flexibility that it
provides.  By that time, though, chances are good that the code which
implements this extra argument has been broken in some subtle way which was
never noticed - because it has never been used.  Or, when the need for
extra flexibility arises, it does not do so in a way which matches the
programmer's early expectation.  Kernel developers will routinely submit
patches to remove unused arguments; they should, in general, not be added
in the first place.
항상 모든 호출자에 의해 0으로 전달되는 인수를 가진 함수가 있다고 가정하자.
혹시 누군가가 사용할 수 있으니 유연하게 그 인수를 유지할 수 있다.
이 경우 미묘하게 잘못 되어도 사용된적이 없기 때문에 발견되지 않을 확률이 높다.
막상 여분의 유연성을 위해 필요할 때도 프로그래머의 기대처럼 작동하지 않는다. 
커널 개발자들은 사용되지 않는 인수를 제거하는 패치를 주기적으로 제출한다. 
일반적으로, 그런 인수는 애초에 추가되지 않았어야 한다.

Abstraction layers which hide access to hardware - often to allow the bulk
of a driver to be used with multiple operating systems - are especially
frowned upon.  Such layers obscure the code and may impose a performance
penalty; they do not belong in the Linux kernel.
하드웨어 드라이버를 여러 운영 체제에서 사용할 수 있도록 하드웨어 액세스를
숨기는 추상화층은 특히 못마땅하게 생각된다. 이러한 층들은 코드를 모호하게하고
성능을 떨어뜨릴 수 있어서 리눅스 커널에는 포함되지 않는다.

On the other hand, if you find yourself copying significant amounts of code
from another kernel subsystem, it is time to ask whether it would, in fact,
make sense to pull out some of that code into a separate library or to
implement that functionality at a higher level.  There is no value in
replicating the same code throughout the kernel.
한편, 당신이 다른 커널 서브 시스템에서 상당한 양의 코드를 복사 한 경우,
별도의 라이브러리로 코드의 일부를 이동시킬지 높은 수준에서 구현할지
결정해야 한다. 커널에 걸쳐 동일한 코드가 중복되는 것은 가치가 없다.


* #ifdef and preprocessor use in general

The C preprocessor seems to present a powerful temptation to some C
programmers, who see it as a way to efficiently encode a great deal of
flexibility into a source file.  But the preprocessor is not C, and heavy
use of it results in code which is much harder for others to read and
harder for the compiler to check for correctness.  Heavy preprocessor use
is almost always a sign of code which needs some cleanup work.
C 전처리기를 C프로그래머에게 효율적으로 소스 파일에 상당한 유연성을 
인코딩할수 있는 방법으로 강력한 유혹을 제시 할 것이다. 그러나 전처리기는 C가 아니며,
많이 사용하면 가독성이 떨어지고 컴파일러가 정확성을 확인하기 힘들어 진다.
과도한 전처리기 사용은 거의 항상 정리 작업이 필요하다는 코드의 표시이다.

Conditional compilation with #ifdef is, indeed, a powerful feature, and it
is used within the kernel.  But there is little desire to see code which is
sprinkled liberally with #ifdef blocks.  As a general rule, #ifdef use
should be confined to header files whenever possible.
Conditionally-compiled code can be confined to functions which, if the code
is not to be present, simply become empty.  The compiler will then quietly
optimize out the call to the empty function.  The result is far cleaner
code which is easier to follow.
#ifdef와 조건부 컴파일은 강력한 기능이며 커널 내에서 사용된다. 
그러나 #ifdef 블록을 자유롭게 뿌린 코드를 보고 싶지는 않다. 
일반적으로, #ifdef 사용은 가능한한 헤더 파일에 국한되어야한다.
조건부 컴파일 된 코드는 단순히 빈되고, 코드가 존재하지 않을 경우 기능에 국한 될 수있다.
컴파일러는 조용히 빈 함수 호출을 최적화한다. 결과는 따라하기 쉬운 훨씬 깔끔한 코드이다.

C preprocessor macros present a number of hazards, including possible
multiple evaluation of expressions with side effects and no type safety.
If you are tempted to define a macro, consider creating an inline function
instead.  The code which results will be the same, but inline functions are
easier to read, do not evaluate their arguments multiple times, and allow
the compiler to perform type checking on the arguments and return value.
C 전처리기 매크로는 표현식의 다양한 계산결과 등 부작용과 타입 세이프티 미지원 등
위험 요소를 갖고있다. 만약 매크로를 사용하고 싶은 경우, 대신 인라인 함수 사용을
고려 할 수 있다. 결과 코드는 동일하지만, 인라인 함수가 가독성이 좋고 인수를 여러번
평가하지않고 컴파일러가 인수 및 반환 값에 유형 검사를 수행 할 수 있다.


* Inline functions

Inline functions present a hazard of their own, though.  Programmers can
become enamored of the perceived efficiency inherent in avoiding a function
call and fill a source file with inline functions.  Those functions,
however, can actually reduce performance.  Since their code is replicated
at each call site, they end up bloating the size of the compiled kernel.
That, in turn, creates pressure on the processor's memory caches, which can
slow execution dramatically.  Inline functions, as a rule, should be quite
small and relatively rare.  The cost of a function call, after all, is not
that high; the creation of large numbers of inline functions is a classic
example of premature optimization.
인라인 함수는 위험요소를 갖고 있지만, 프로그래머는 함수호출을 피하고
소스파일을 인라인 함수로 채워 고유의 효율성에 매혹될 수 있다. 그러나 이러한 기능은
실제로 성능을 감소시킬 수 있다. 이들 코드는 각 호출 위치에 복제되기 때문에
그들은 컴파일 커널의 크기를 팽창시키고 프로세서의 메모리 캐시에 압력을 주어 
극적으로 실행속도를 느려지게 할 수 있다. 인라인 함수는 원칙적으로 아주 작고 드물게 사용해야한다.
결국 함수 호출의 비용은 그렇게 높지 않다. 많은 인라인 함수 생성은 조기 최적화의 고전적인 예이다.

In general, kernel programmers ignore cache effects at their peril.  The
classic time/space tradeoff taught in beginning data structures classes
often does not apply to contemporary hardware.  Space *is* time, in that a
larger program will run slower than one which is more compact.
일반적으로 커널 프로그래머는 캐시 효과를 무시한다. 데이터 구조 수업의
시작에서 배운 시간/공간 트레이드오프는 종종 현대 하드웨어에 적용되지 않는다. 
더 큰 프로그램이 작은 프로그램보다 느리게 실행된다는 점에서 공간이 곧 시간이다.

More recent compilers take an increasingly active role in deciding whether
a given function should actually be inlined or not.  So the liberal
placement of "inline" keywords may not just be excessive; it could also be
irrelevant.
최근의 컴파일러는 주어진 함수가 실제 인라인함수로 사용되는지 여부를 결정하는데 적극적인 역할을 한다. 
그래서 인라인 함수의 자유로운 배치는 과도하지 않게 조절 되며 또한 관련이 없을 수 있다.


* Locking

In May, 2006, the "Devicescape" networking stack was, with great
fanfare, released under the GPL and made available for inclusion in the
mainline kernel.  This donation was welcome news; support for wireless
networking in Linux was considered substandard at best, and the Devicescape
stack offered the promise of fixing that situation.  Yet, this code did not
actually make it into the mainline until June, 2007 (2.6.22).  What
happened?
2006년 5월 "Devicescape" 네트워킹 스택은 GPL라이센스로 메인라인에 포함되었다.
이 기부는 희소식이었다. 이전 리눅스 무선 네트워킹에 대한 지원은 수준 이하였고
Devicescape 스택은 그런 상황을 개선하는 제안이었다. 그러나 이 코드는 실제로
2007년 6월(2.6.22)까지 메인라인에 포함되지 않았다. 무슨 일이 있었을까?

This code showed a number of signs of having been developed behind
corporate doors.  But one large problem in particular was that it was not
designed to work on multiprocessor systems.  Before this networking stack
(now called mac80211) could be merged, a locking scheme needed to be
retrofitted onto it.
이 코드는 기업의 문 뒤에서 개발 되었다. 그러나 하나의 큰 문제는 이것이 
멀티프로세서 시스템에서 작동하도록 설계되지 않았다는 것이다. 
이 네트워킹 스택(mac80211)은 머지되기 전에 lock방식이 추가되어야 했다.

Once upon a time, Linux kernel code could be developed without thinking
about the concurrency issues presented by multiprocessor systems.  Now,
however, this document is being written on a dual-core laptop.  Even on
single-processor systems, work being done to improve responsiveness will
raise the level of concurrency within the kernel.  The days when kernel
code could be written without thinking about locking are long past.
옛날 옛적엔 리눅스 커널 코드는 멀티프로세서 시스템에 의해 발생되는 동시성 문제를
고려하지 않고 개발 될 수 있었다. 그러나 지금,이 문서는 듀얼 코어 노트북에서 기록되고 있다.
심지어 싱글프로세서 시스템에서 응답성을 개선하기 위한 작업은 커널내에서 동시성의
수준을 올릴 것이다. 커널 코드가 lock에 대해 생각하지 않고 작성되던 시절은 오래전에 끝났다.

Any resource (data structures, hardware registers, etc.) which could be
accessed concurrently by more than one thread must be protected by a lock.
New code should be written with this requirement in mind; retrofitting
locking after the fact is a rather more difficult task.  Kernel developers
should take the time to understand the available locking primitives well
enough to pick the right tool for the job.  Code which shows a lack of
attention to concurrency will have a difficult path into the mainline.
하나 이상의 스레드에 의해 동시에 액세스 될 수있는 모든 자원(데이터 구조, 하드웨어 레지스터 등)
은 lock에 의해 보호 되어야한다. 새로운 코드는 이 요구사항을 염두에 두고 작성해야한다.
사후 lock 추가는 오히려 더 어려운 작업이다. 커널 개발자는 작업에 적합한 도구를 선택할수 있도록
충분히 가능한 lock 기본 요소를 이해하는 시간을 가져야 한다. 동시성에 대한 관심이 부족한 코드는
메인라인에 포함되기 어렵다.


* Regressions

One final hazard worth mentioning is this: it can be tempting to make a
change (which may bring big improvements) which causes something to break
for existing users.  This kind of change is called a "regression," and
regressions have become most unwelcome in the mainline kernel.  With few
exceptions, changes which cause regressions will be backed out if the
regression cannot be fixed in a timely manner.  Far better to avoid the
regression in the first place.

It is often argued that a regression can be justified if it causes things
to work for more people than it creates problems for.  Why not make a
change if it brings new functionality to ten systems for each one it
breaks?  The best answer to this question was expressed by Linus in July,
2007:

	So we don't fix bugs by introducing new problems.  That way lies
	madness, and nobody ever knows if you actually make any real
	progress at all. Is it two steps forwards, one step back, or one
	step forward and two steps back?

(http://lwn.net/Articles/243460/).

An especially unwelcome type of regression is any sort of change to the
user-space ABI.  Once an interface has been exported to user space, it must
be supported indefinitely.  This fact makes the creation of user-space
interfaces particularly challenging: since they cannot be changed in
incompatible ways, they must be done right the first time.  For this
reason, a great deal of thought, clear documentation, and wide review for
user-space interfaces is always required.



4.2: CODE CHECKING TOOLS

For now, at least, the writing of error-free code remains an ideal that few
of us can reach.  What we can hope to do, though, is to catch and fix as
many of those errors as possible before our code goes into the mainline
kernel.  To that end, the kernel developers have put together an impressive
array of tools which can catch a wide variety of obscure problems in an
automated way.  Any problem caught by the computer is a problem which will
not afflict a user later on, so it stands to reason that the automated
tools should be used whenever possible.

The first step is simply to heed the warnings produced by the compiler.
Contemporary versions of gcc can detect (and warn about) a large number of
potential errors.  Quite often, these warnings point to real problems.
Code submitted for review should, as a rule, not produce any compiler
warnings.  When silencing warnings, take care to understand the real cause
and try to avoid "fixes" which make the warning go away without addressing
its cause.

Note that not all compiler warnings are enabled by default.  Build the
kernel with "make EXTRA_CFLAGS=-W" to get the full set.

The kernel provides several configuration options which turn on debugging
features; most of these are found in the "kernel hacking" submenu.  Several
of these options should be turned on for any kernel used for development or
testing purposes.  In particular, you should turn on:

 - ENABLE_WARN_DEPRECATED, ENABLE_MUST_CHECK, and FRAME_WARN to get an
   extra set of warnings for problems like the use of deprecated interfaces
   or ignoring an important return value from a function.  The output
   generated by these warnings can be verbose, but one need not worry about
   warnings from other parts of the kernel.

 - DEBUG_OBJECTS will add code to track the lifetime of various objects
   created by the kernel and warn when things are done out of order.  If
   you are adding a subsystem which creates (and exports) complex objects
   of its own, consider adding support for the object debugging
   infrastructure.

 - DEBUG_SLAB can find a variety of memory allocation and use errors; it
   should be used on most development kernels.

 - DEBUG_SPINLOCK, DEBUG_ATOMIC_SLEEP, and DEBUG_MUTEXES will find a
   number of common locking errors.

There are quite a few other debugging options, some of which will be
discussed below.  Some of them have a significant performance impact and
should not be used all of the time.  But some time spent learning the
available options will likely be paid back many times over in short order. 

One of the heavier debugging tools is the locking checker, or "lockdep."
This tool will track the acquisition and release of every lock (spinlock or
mutex) in the system, the order in which locks are acquired relative to
each other, the current interrupt environment, and more.  It can then
ensure that locks are always acquired in the same order, that the same
interrupt assumptions apply in all situations, and so on.  In other words,
lockdep can find a number of scenarios in which the system could, on rare
occasion, deadlock.  This kind of problem can be painful (for both
developers and users) in a deployed system; lockdep allows them to be found
in an automated manner ahead of time.  Code with any sort of non-trivial
locking should be run with lockdep enabled before being submitted for
inclusion. 

As a diligent kernel programmer, you will, beyond doubt, check the return
status of any operation (such as a memory allocation) which can fail.  The
fact of the matter, though, is that the resulting failure recovery paths
are, probably, completely untested.  Untested code tends to be broken code;
you could be much more confident of your code if all those error-handling
paths had been exercised a few times.

The kernel provides a fault injection framework which can do exactly that,
especially where memory allocations are involved.  With fault injection
enabled, a configurable percentage of memory allocations will be made to
fail; these failures can be restricted to a specific range of code.
Running with fault injection enabled allows the programmer to see how the
code responds when things go badly.  See
Documentation/fault-injection/fault-injection.txt for more information on
how to use this facility.

Other kinds of errors can be found with the "sparse" static analysis tool.
With sparse, the programmer can be warned about confusion between
user-space and kernel-space addresses, mixture of big-endian and
small-endian quantities, the passing of integer values where a set of bit
flags is expected, and so on.  Sparse must be installed separately (it can
be found at https://sparse.wiki.kernel.org/index.php/Main_Page if your
distributor does not package it); it can then be run on the code by adding
"C=1" to your make command.

The "Coccinelle" tool (http://coccinelle.lip6.fr/) is able to find a wide
variety of potential coding problems; it can also propose fixes for those
problems.  Quite a few "semantic patches" for the kernel have been packaged
under the scripts/coccinelle directory; running "make coccicheck" will run
through those semantic patches and report on any problems found.  See
Documentation/coccinelle.txt for more information.

Other kinds of portability errors are best found by compiling your code for
other architectures.  If you do not happen to have an S/390 system or a
Blackfin development board handy, you can still perform the compilation
step.  A large set of cross compilers for x86 systems can be found at 

	http://www.kernel.org/pub/tools/crosstool/

Some time spent installing and using these compilers will help avoid
embarrassment later.


4.3: DOCUMENTATION

Documentation has often been more the exception than the rule with kernel
development.  Even so, adequate documentation will help to ease the merging
of new code into the kernel, make life easier for other developers, and
will be helpful for your users.  In many cases, the addition of
documentation has become essentially mandatory.

The first piece of documentation for any patch is its associated
changelog.  Log entries should describe the problem being solved, the form
of the solution, the people who worked on the patch, any relevant
effects on performance, and anything else that might be needed to
understand the patch.  Be sure that the changelog says *why* the patch is
worth applying; a surprising number of developers fail to provide that
information.

Any code which adds a new user-space interface - including new sysfs or
/proc files - should include documentation of that interface which enables
user-space developers to know what they are working with.  See
Documentation/ABI/README for a description of how this documentation should
be formatted and what information needs to be provided.

The file Documentation/kernel-parameters.txt describes all of the kernel's
boot-time parameters.  Any patch which adds new parameters should add the
appropriate entries to this file.

Any new configuration options must be accompanied by help text which
clearly explains the options and when the user might want to select them.

Internal API information for many subsystems is documented by way of
specially-formatted comments; these comments can be extracted and formatted
in a number of ways by the "kernel-doc" script.  If you are working within
a subsystem which has kerneldoc comments, you should maintain them and add
them, as appropriate, for externally-available functions.  Even in areas
which have not been so documented, there is no harm in adding kerneldoc
comments for the future; indeed, this can be a useful activity for
beginning kernel developers.  The format of these comments, along with some
information on how to create kerneldoc templates can be found in the file
Documentation/kernel-doc-nano-HOWTO.txt.

Anybody who reads through a significant amount of existing kernel code will
note that, often, comments are most notable by their absence.  Once again,
the expectations for new code are higher than they were in the past;
merging uncommented code will be harder.  That said, there is little desire
for verbosely-commented code.  The code should, itself, be readable, with
comments explaining the more subtle aspects.

Certain things should always be commented.  Uses of memory barriers should
be accompanied by a line explaining why the barrier is necessary.  The
locking rules for data structures generally need to be explained somewhere.
Major data structures need comprehensive documentation in general.
Non-obvious dependencies between separate bits of code should be pointed
out.  Anything which might tempt a code janitor to make an incorrect
"cleanup" needs a comment saying why it is done the way it is.  And so on.


4.4: INTERNAL API CHANGES

The binary interface provided by the kernel to user space cannot be broken
except under the most severe circumstances.  The kernel's internal
programming interfaces, instead, are highly fluid and can be changed when
the need arises.  If you find yourself having to work around a kernel API,
or simply not using a specific functionality because it does not meet your
needs, that may be a sign that the API needs to change.  As a kernel
developer, you are empowered to make such changes.

There are, of course, some catches.  API changes can be made, but they need
to be well justified.  So any patch making an internal API change should be
accompanied by a description of what the change is and why it is
necessary.  This kind of change should also be broken out into a separate
patch, rather than buried within a larger patch.

The other catch is that a developer who changes an internal API is
generally charged with the task of fixing any code within the kernel tree
which is broken by the change.  For a widely-used function, this duty can
lead to literally hundreds or thousands of changes - many of which are
likely to conflict with work being done by other developers.  Needless to
say, this can be a large job, so it is best to be sure that the
justification is solid.  Note that the Coccinelle tool can help with
wide-ranging API changes.

When making an incompatible API change, one should, whenever possible,
ensure that code which has not been updated is caught by the compiler.
This will help you to be sure that you have found all in-tree uses of that
interface.  It will also alert developers of out-of-tree code that there is
a change that they need to respond to.  Supporting out-of-tree code is not
something that kernel developers need to be worried about, but we also do
not have to make life harder for out-of-tree developers than it needs to
be.
